{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49955324-442b-434d-8b2b-51499d87ab12",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# Cluster Filtering\n",
    "\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "While the anomaly detector in Muzlin works well to inform the user if new data belongs to the fitted dataset group, what it lacks is whether the new data belongs to many or one sub-group within the training dataset. \n",
    "\n",
    "Why is this useful? \n",
    "\n",
    "Say that you have a vector index and want to provide the top 10 retrieved context to an LLM to answer th user's question.\n",
    "While the user's question belongs to the training dataset (e.g. the vector index), the retrieved context may be significantly seperated from the question within the vector space and not really provide much or meaningful context.\n",
    "\n",
    "A simple approach might be to use the consine similarity and set a passing threshold.\n",
    "Another approach provided in Muzlin takes a more automated apoproach.\n",
    "\n",
    "That is where clustering filters come in and can be used as a second layer filter after anomaly detection.\n",
    "\n",
    "# Let's get started!\n",
    "\n",
    "To begin, first it is recommended to install the necessary libraries to work with the notebooks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a381da-8029-4a53-8c82-9f6bbd981282",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q muzlin[notebook]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d974334-af2d-495d-9413-38cb6d0b7faa",
   "metadata": {},
   "source": [
    "Now that we have everything installed, let's import the precomputed encoded textual vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b984668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vectors = np.load('vectors.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be91a00-0c1b-4364-a9ce-cbf251abff55",
   "metadata": {},
   "source": [
    "<br>\n",
    "Now we can build our clustering filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2f418-3571-4832-bbe5-5afaabc7c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from muzlin.anomaly import OutlierCluster\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Let's initialize a clustering method. Don't worry about the n_clusters, this will be dynamically reset\n",
    "clust = KMeans(n_clusters=2, random_state=1234)\n",
    "\n",
    "# Since this is linked to the number of retrieved context a useful component is the top-k retreival amount\n",
    "n_retrieve = 10 # Retrive 10 documents from the vector index\n",
    "\n",
    "\n",
    "# Set mlflow to true to log the experiment\n",
    "#mlflow.set_experiment('outlier_model')\n",
    "clf = OutlierCluster(mlflow=False, method=clust, n_retrieve=n_retrieve)\n",
    "clf.fit(vectors)\n",
    "#mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a749b8-f2c0-4bd3-b451-870a3b92bd27",
   "metadata": {},
   "source": [
    "<br>\n",
    "Perhaps a quick look at the cluster stats will be helpful before we continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319f568f-d9fc-4f20-943f-8bbdbd9f84ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 40\n",
      "Mean number of vectors per cluster: 20.225\n",
      "Median number of vectors per cluster: 19.0\n",
      "Standard deviation between the number of vectors per cluster: 6.897417995163118\n"
     ]
    }
   ],
   "source": [
    "n_col = len(np.unique(clf.labels_))\n",
    "_, n_counts = np.unique(clf.labels_, return_counts=True)\n",
    "print('Number of clusters:', n_col)\n",
    "print('Mean number of vectors per cluster:', np.mean(n_counts)) \n",
    "print('Median number of vectors per cluster:', np.median(n_counts))\n",
    "print('Standard deviation between the number of vectors per cluster:',np.std(n_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44828db-cca8-4256-82a6-002ecfaa78d7",
   "metadata": {},
   "source": [
    "<br>\n",
    "A nice way to visualize this is to decompose the vectors and inspect the 3D plot of all the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c08d25a-8038-4a24-b7c1-b13cd737aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.decomposition import PCA as PCA_decomp\n",
    "\n",
    "# Create a colormap with 40 distinct colors\n",
    "cmap = plt.get_cmap('tab20')  # You can use other colormaps like 'tab20', 'viridis', etc.\n",
    "colors = [cmap(i / n_col) for i in range(n_col)]  # Generate colors for 40 labels\n",
    "\n",
    "\n",
    "# Create a decomposition model and transform the data\n",
    "#decomp = TSNE(n_components=3, perplexity=5, random_state=42, init='pca', learning_rate='auto', metric='cosine')\n",
    "decomp = PCA_decomp(n_components=3)\n",
    "vis_dims = decomp.fit_transform(vectors)\n",
    "\n",
    "x = vis_dims[:, 0]\n",
    "y = vis_dims[:, 1]\n",
    "z = vis_dims[:, 2]\n",
    "\n",
    "labels = clf.labels_\n",
    "\n",
    "# Initialize an empty list to hold the scatter plots\n",
    "scatter_list = []\n",
    "\n",
    "# Plot each label with a unique color\n",
    "for i, label in enumerate(np.unique(labels)):\n",
    "    scatter_list.append(go.Scatter3d(\n",
    "        x=x[labels == label],\n",
    "        y=y[labels == label],\n",
    "        z=z[labels == label],\n",
    "        mode='markers',\n",
    "        marker=dict(size=1.5, color=f'rgb({colors[i][0] * 255},{colors[i][1] * 255},{colors[i][2] * 255})'),\n",
    "        name=f'Label {label}'\n",
    "    ))\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure(data=scatter_list)\n",
    "\n",
    "\n",
    "# Set the title\n",
    "fig.update_layout(title_text='Clusters',\n",
    "                 width=600, height=600)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a0f34d-4b0d-44e7-9664-68cd755fa736",
   "metadata": {},
   "source": [
    "<br>\n",
    "So now that we have a cluster filter, the next step is to test to see how it performs with retrieved documents\n",
    "<br>\n",
    "However, to do this we will need to first build an vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80dab305-18ac-477c-a449-be0ad73471a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "df = pd.read_csv('bigbio_scifact.csv')\n",
    "\n",
    "texts = df['data'].values.tolist()\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name='BAAI/bge-small-en-v1.5')\n",
    "\n",
    "db = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "#db.save_local(\"faiss_index\")\n",
    "#db = FAISS.load_local(\"faiss_index\", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8673c403-6e13-4824-b9c8-bc16e5577ade",
   "metadata": {},
   "source": [
    "Any document retriever will work. \n",
    "\n",
    "Muzlin aslo has a wrapper for LangChain and LlamaIndex vector indeces. I you want to keep everything consistent within Muzlin, this vector index can be loaded into a local class for handeling Langchain indexes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fab85f8-a840-40d7-92c9-225a03439d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from muzlin.index import LangchainIndex\n",
    "\n",
    "db = LangchainIndex(index=db, top_k=n_retrieve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b6fe77-b04c-42c8-8254-4ee67da43b66",
   "metadata": {},
   "source": [
    "Let's now create a function for retrieving the stored documents based on the user's query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e1b8c6a-3dbb-4fe5-9c8e-f6dfbc1ce047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from muzlin.encoders import HuggingFaceEncoder\n",
    "\n",
    "def get_doc_vectors(index, encoder, query):\n",
    "\n",
    "    documents = index(query)\n",
    "    \n",
    "    doc_vectors = []\n",
    "    for doc in documents:\n",
    "        print(doc)\n",
    "        doc_embed = encoder([doc])\n",
    "        doc_array = np.array(doc_embed).reshape(1, -1)\n",
    "        doc_vectors.append(doc_array.ravel())\n",
    "\n",
    "    print('\\n')\n",
    "    return doc_vectors\n",
    "\n",
    "encoder = HuggingFaceEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a79992-1060-439d-a8d6-ff4cff0b0650",
   "metadata": {},
   "source": [
    "The two queries below were shown to pass the anomaly threshold in the last notebook example\n",
    "\n",
    "What results will the clustering filter test say?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff84e078-804e-41dd-9424-f05df76c0386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-PBA treatment raises endoplasmic reticulum stress in response to general endoplasmic reticulum stress markers.\n",
      "4-PBA treatment decreases endoplasmic reticulum stress in response to general endoplasmic reticulum stress markers.\n",
      "ATF4 is a general endoplasmic reticulum stress marker.\n",
      "BiP is a general endoplasmic reticulum stress marker.\n",
      "CHOP is a general endoplasmic reticulum stress marker.\n",
      "Treatment with a protein named FN impairs regenerative abilities of aged muscles.\n",
      "Treatment with a protein named FN restores regenerative abilities of aged muscles.\n",
      "Cholesterol loading induces KLF4 expression in VSMCs, resulting in the expression of pro-inflammatory cytokines.\n",
      "PCSK9 inhibitors decrease plasma Lp(a) levels.\n",
      "Chenodeoxycholic acid treatment decreases brown adipose tissue activity.\n",
      "\n",
      "\n",
      "40mg/day dosage of folic acid and 2mg/day dosage of vitamin B12 does not affect chronic kidney disease (CKD) progression.\n",
      "Intake of folic acid (FA) and vitamin B6 (VB6) increases levels of homocysteine.\n",
      "A deficiency of folate increases blood levels of homocysteine.\n",
      "Intake of folic acid (FA) and vitamin B6 (VB6) reduces levels of homocysteine.\n",
      "Folate and vitamin B12 levels influence the association between homocysteine and preeclampsia.\n",
      "Chinese individuals with TT homozygosity in the MTHFR gene are more vulnerable to strokes caused by low levels of folate intake.\n",
      "Insulin decreases risk of severe kidney failure.\n",
      "Angiotensin converting enzyme inhibitors are associated with decreased risk for functional renal insufficiency.\n",
      "Chenodeoxycholic acid treatment decreases brown adipose tissue activity.\n",
      "Chenodeoxycholic acid treatment increases brown adipose tissue activity.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query1 = 'What treatment raises endoplasmic reticulum stress?'\n",
    "query2 = 'If I take too much folic acid will a side effect be kidney disease?'\n",
    "\n",
    "q1_doc_vecs = get_doc_vectors(db, encoder, query1)\n",
    "q2_doc_vecs = get_doc_vectors(db, encoder, query2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a997846a-9e58-461e-b3f5-e139d6bb686d",
   "metadata": {},
   "source": [
    "Just by visual inspection of the retrived documents above we can see that the first query can be fully answered by the context provided.\n",
    "However, the second while it seems like the context may appear to answer the query, none of context fully answers the query.\n",
    "\n",
    "There are three tests that are applied during clustering filtering:\n",
    "\n",
    "- Is thre retieved context from an optimal number of clusters (e.g. not to dense or sparse in detail)\n",
    "- Does the query and the retrieved context really constitute a realistic cluster with respect to the entire fitted data (checks if this pseudo-cluster is similar in size to the general cluster size within the vector index)\n",
    "- Factoring in the density of the retieved documents cluster, does the query really belong to this cluster? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30973aef-8543-49e1-a51d-613f4d9266d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For query 1 the three tests are as follows:  0 0 0\n",
      "For query 2 the three tests are as follows:  0 1 1\n"
     ]
    }
   ],
   "source": [
    "query1_vec = np.array(encoder([query1])).reshape(1,-1)\n",
    "query2_vec = np.array(encoder([query2])).reshape(1,-1)\n",
    "\n",
    "clust_class1, topk_class1, sep_class1 = clf.predict(query1_vec, q1_doc_vecs)\n",
    "clust_class2, topk_class2, sep_class2 = clf.predict(query2_vec, q2_doc_vecs)\n",
    "\n",
    "print('For query 1 the three tests are as follows: ', clust_class1, topk_class1, sep_class1) # inlier\n",
    "print('For query 2 the three tests are as follows: ', clust_class2, topk_class2, sep_class2) # outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be93632b-0722-42af-ac2f-fb96bb9d2f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "0a54084e6b208ee8d1ce3989ffc20924477a5f55f5a43e22e699a6741623861e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
